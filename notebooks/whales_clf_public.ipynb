{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4O4kyTYg0i8I"
   },
   "source": [
    "# Importing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fq0fJcaeXEWc"
   },
   "outputs": [],
   "source": [
    "# ! pip3 install -q kaggle\n",
    "\n",
    "# ! mkdir ~/.kaggle\n",
    "# ! cp /home/ignatlegeza/kaggle/kaggle.json ~/.kaggle/\n",
    "# ! chmod 600 ~/.kaggle/kaggle.json\n",
    "\n",
    "# ! kaggle competitions list\n",
    "# ! kaggle competitions download -c humpback-whale-identification -p ./data/\n",
    "\n",
    "# ! unzip -q ./data/test.zip -d ./data/test\n",
    "# ! unzip -q ./data/train.zip -d ./data/train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "fa198cf62a1f63298f9f5b41d144dda811084027",
    "colab": {},
    "colab_type": "code",
    "id": "eJwkZEDpW9rI"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import time\n",
    "import pickle\n",
    "from functools import partial\n",
    "import multiprocessing\n",
    "import multiprocessing.dummy\n",
    "num_cores = multiprocessing.cpu_count()\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from PIL import Image\n",
    "import cv2\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.utils.data.sampler import BatchSampler # Sampler,\n",
    "cuda = torch.device('cuda')\n",
    "cpu = torch.device('cpu')\n",
    "\n",
    "import torchvision\n",
    "from torchvision import models, transforms\n",
    "\n",
    "from tqdm import tqdm\n",
    "from IPython.display import clear_output\n",
    "\n",
    "gdrive_path = './models_logs/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "129702005d4fd98f855481b8973b1102b366dc35",
    "colab": {},
    "colab_type": "code",
    "id": "XleZI3RfW9rS"
   },
   "outputs": [],
   "source": [
    "labels = pd.read_csv('./data/train.csv')\n",
    "\n",
    "# labels - таблица вида: имя картинки, лейбл кита на ней"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "6b4d0bff12110221fa28b5085062dd74bcb50565",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "colab_type": "code",
    "id": "VMyMvpIpW9rd",
    "outputId": "3e8b4eba-b713-41c6-fa36-197865e63e39"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Image</th>\n",
       "      <th>Id</th>\n",
       "      <th>Id_enc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0000e88ab.jpg</td>\n",
       "      <td>w_f48451c</td>\n",
       "      <td>4786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0001f9222.jpg</td>\n",
       "      <td>w_c3d896a</td>\n",
       "      <td>3808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00029d126.jpg</td>\n",
       "      <td>w_20df2c5</td>\n",
       "      <td>662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00050a15a.jpg</td>\n",
       "      <td>new_whale</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0005c1ef8.jpg</td>\n",
       "      <td>new_whale</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Image         Id  Id_enc\n",
       "0  0000e88ab.jpg  w_f48451c    4786\n",
       "1  0001f9222.jpg  w_c3d896a    3808\n",
       "2  00029d126.jpg  w_20df2c5     662\n",
       "3  00050a15a.jpg  new_whale       0\n",
       "4  0005c1ef8.jpg  new_whale       0"
      ]
     },
     "execution_count": 4,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# для удобства кодируем лейблы числами\n",
    "\n",
    "lblenc = LabelEncoder()\n",
    "\n",
    "lblenc.fit(labels['Id'])\n",
    "labels_encoded = lblenc.transform(labels['Id'])\n",
    "labels['Id_enc'] = labels_encoded\n",
    "\n",
    "nw_label_enc = lblenc.transform(['new_whale'])[0]\n",
    "\n",
    "labels.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "2f16114b06aa741889262e4e511caa36ead959b2",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "4Xsgbz7fW9ro",
    "outputId": "618860e4-76f9-48ec-e485-29e675d4abcf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train size:  25361\n",
      "num of classes:  5005\n"
     ]
    }
   ],
   "source": [
    "print('train size: ', labels.shape[0])\n",
    "print('num of classes: ', lblenc.classes_.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "22656e023c125de400658d841327afc45740a262",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "colab_type": "code",
    "id": "_p-AQeL-W9r4",
    "outputId": "3d9c0293-b20c-4778-9bb7-02fbbc7f2b38"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>9664</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>712</td>\n",
       "      <td>73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3029</td>\n",
       "      <td>65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3049</td>\n",
       "      <td>62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>64</td>\n",
       "      <td>61</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   label  count\n",
       "0      0   9664\n",
       "1    712     73\n",
       "2   3029     65\n",
       "3   3049     62\n",
       "4     64     61"
      ]
     },
     "execution_count": 6,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# посчитаем как часто встречается каждый из лейблов\n",
    "\n",
    "labels_counter = pd.DataFrame(\n",
    "    {'label': np.unique(labels['Id_enc'], return_counts=True)[0],\n",
    "     'count': np.unique(labels['Id_enc'], return_counts=True)[1]}\n",
    ")\n",
    "\n",
    "labels_counter = labels_counter.sort_values(by='count', ascending=False)\n",
    "labels_counter = labels_counter.reset_index(drop=True)\n",
    "\n",
    "labels_counter.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "ed8adafd11a814cfeb07decc8d830ce973295e32",
    "colab_type": "text",
    "id": "0qGUXo8KW9sL"
   },
   "source": [
    "# Data clearing and making validation\n",
    "\n",
    "Наша табличка labels является по сути словарем с именами и лейблами всей тренировочной выборки.  \n",
    "В первом подходе к задаче мы совсем не хотим работать с лейблами у которых только одна картинка (одиночки), потому что к ним просто не найти позитивов. Тренироваться на таких мы не будем, но при получении предиктов мы будем считать расстояние до них.  \n",
    "Формируя валидационный датасет мы почти вручную достанем 4500 картинок из labels.  \n",
    "Логика будет следующей:\n",
    "1. Случайно достаем int(4500 x 0.3) картинок с лейблом new_whale.\n",
    "2. Для лейблов с двумя и тремя картинками правило следующее: бежим по таким лейблам и достаем одну случайную картинку в тест. Так бежим пока не достигнем максимума, заданного в словаре max_chosen_labels: int(4500 x 0.15) и int(4500 x 0.05).\n",
    "3. Исключаем из labels все картинки с лейблом new_whale и лейблами, состоящими из 1, 2, 3 картинок. Из получившегося множества рандомно добираем оставшуюся часть валидации int(4500 x 0.5)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "4c5029f0774051d4803c368b51699ec7b19e1b1e",
    "colab": {},
    "colab_type": "code",
    "id": "iwYCIjq-W9sO"
   },
   "outputs": [],
   "source": [
    "labels_set_initial = set(labels['Id_enc'])\n",
    "\n",
    "# label_to_indices_initial -- словарь вида: лейбл - индексы картинок с этим лейблом\n",
    "label_to_indices_initial = {label: np.where(labels['Id_enc'] == label)[0] \n",
    "                            for label in labels_set_initial}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "d0f991be97040f879a9bf13a84a9ad9e2a8132db",
    "colab": {},
    "colab_type": "code",
    "id": "0GjDOLHUW9sV"
   },
   "outputs": [],
   "source": [
    "# исключаем из labels лейблы-одиночки\n",
    "\n",
    "lonely_labels = []\n",
    "for key in label_to_indices_initial:\n",
    "    if len(label_to_indices_initial[key]) == 1:\n",
    "        lonely_labels.append(key)\n",
    "\n",
    "labels_without_singles = labels[~labels['Id_enc'].isin(lonely_labels)]\n",
    "labels_without_singles = labels_without_singles.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "bb7d670741fd5f176412633c2425e20d7bc82a35",
    "colab": {},
    "colab_type": "code",
    "id": "ejkb3eFyW9sk"
   },
   "outputs": [],
   "source": [
    "random_state = np.random.RandomState(42)\n",
    "\n",
    "max_chosen_labels = {\n",
    "    2: int(4500 * 0.15),\n",
    "    3: int(4500 * 0.05),\n",
    "    'other': int(4500 * 0.5)\n",
    "}\n",
    "\n",
    "current_chosen_labels = {\n",
    "    2: 0,\n",
    "    3: 0,\n",
    "    'other': 0\n",
    "}\n",
    "val_indxs = np.empty(0)\n",
    "for key in label_to_indices_initial:\n",
    "    # забиваем 30% валидации картинками с лейблом new_whale\n",
    "    if key == nw_label_enc:\n",
    "        chosen_indxs = random_state.choice(label_to_indices_initial[key], int(4500*0.3), replace=False)\n",
    "        val_indxs = np.append(val_indxs, chosen_indxs)\n",
    "    # забиваем 15% валидации картинками с лейблом из двух картинок (достаем по одной на лейбл)\n",
    "    elif len(label_to_indices_initial[key]) == 2 and \\\n",
    "    current_chosen_labels[2] < max_chosen_labels[2]:\n",
    "        chosen_indxs = random_state.choice(label_to_indices_initial[key], 1)\n",
    "        val_indxs = np.append(val_indxs, chosen_indxs)\n",
    "        current_chosen_labels[2] += 1\n",
    "    # забиваем 5% валидации картинками с лейблом из трех картинок (достаем по одной на лейбл)\n",
    "    elif len(label_to_indices_initial[key]) == 3 and \\\n",
    "    current_chosen_labels[3] < max_chosen_labels[3]:\n",
    "        chosen_indxs = random_state.choice(label_to_indices_initial[key], 1)\n",
    "        val_indxs = np.append(val_indxs, chosen_indxs)\n",
    "        current_chosen_labels[3] += 1\n",
    "\n",
    "# мы сформировали 50% валидации. \n",
    "# теперь сформируем сет с индексами всех new_whale и лейблов с 2 и 3 картинками.\n",
    "indxs_to_exclude_for_val = np.empty(0)\n",
    "indxs_to_exclude_for_val = np.append(indxs_to_exclude_for_val, label_to_indices_initial[nw_label_enc])\n",
    "\n",
    "labels_with_2_3_imgs = np.array(labels_counter[(labels_counter['count'] >= 1) & \n",
    "                                               (labels_counter['count'] <= 3)]['label'])\n",
    "for label in labels_with_2_3_imgs:\n",
    "    indxs_to_exclude_for_val = np.append(indxs_to_exclude_for_val, \n",
    "                                         label_to_indices_initial[label])\n",
    "\n",
    "# исключаем из labels все индексы из сета выше и рандомно добираем оставшиеся 50% валидации\n",
    "chosen_indxs = random_state.choice(\n",
    "    np.array(list(set([*labels.index]) - set(indxs_to_exclude_for_val))), \n",
    "    max_chosen_labels['other'], replace=False\n",
    ")\n",
    "val_indxs = np.append(val_indxs, chosen_indxs)\n",
    "val_indxs = val_indxs.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nwqPG0c6zhEl"
   },
   "outputs": [],
   "source": [
    "# формируем новый трейн без картинок, которые отобрали в валдацию\n",
    "new_train_indxs = np.array(list(set([*labels.index]) - set(val_indxs)))\n",
    "new_train_labels_with = labels.iloc[new_train_indxs]\n",
    "new_train_labels_with = new_train_labels_with.reset_index(drop=True)\n",
    "\n",
    "# уберем из нового трейна лейблы-одиночки, потому что не можем взять для них позитивы\n",
    "labels_set_new = set(new_train_labels_with['Id_enc'])\n",
    "label_to_indices_new = {label: np.where(new_train_labels_with['Id_enc'] == label)[0] \n",
    "                        for label in labels_set_new}\n",
    "\n",
    "lonely_labels_new = []\n",
    "for key in label_to_indices_new:\n",
    "    if len(label_to_indices_new[key]) == 1:\n",
    "        lonely_labels_new.append(key)\n",
    "\n",
    "new_train_labels_without = new_train_labels_with[~new_train_labels_with['Id_enc'].isin(lonely_labels_new)]\n",
    "new_train_labels_without = new_train_labels_without.reset_index(drop=True)\n",
    "\n",
    "val_labels_df = labels.iloc[val_indxs]\n",
    "val_labels_df = val_labels_df.reset_index(drop=True)\n",
    "\n",
    "test_df = os.listdir('./data/test/')\n",
    "test_df = pd.DataFrame({'Image': test_df})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 119
    },
    "colab_type": "code",
    "id": "ZulFxIghuw8q",
    "outputId": "06b123da-3793-42fd-fe67-75fa6b1f501d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initial labels: (25361, 3) \n",
      " initial labels without lonelis: (23288, 3) \n",
      " new train labels with lonelis: (20861, 3) \n",
      " new train labels without lonelis: (18098, 3) \n",
      " val labels with lonelies: (4500, 3) \n",
      " test df: (7960, 1)\n"
     ]
    }
   ],
   "source": [
    "print(\n",
    "    'initial labels:', labels.shape, '\\n',\n",
    "    'initial labels without lonelis:', labels_without_singles.shape, '\\n',\n",
    "    'new train labels with lonelis:', new_train_labels_with.shape, '\\n',\n",
    "    'new train labels without lonelis:', new_train_labels_without.shape, '\\n',\n",
    "    'val labels with lonelies:', val_labels_df.shape, '\\n',\n",
    "    'test df:', test_df.shape\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "IUAsQlfLv9Xz"
   },
   "source": [
    "Итого.  \n",
    "Для тренировки нас интересуют следующие датасеты:\n",
    "\n",
    "*   new_train_labels_without -- на нем мы будем обучаться (новый трейн без одиночек);\n",
    "*   val_labels_df -- на нем мы будем валидироваться, измеряя расстояния до всех картинок из new_train_labels_with (новый трейн с одиночками).\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "7a6d207a49eac2e90414c595b02c055878191303",
    "colab_type": "text",
    "id": "9LoIi_OOW9s0"
   },
   "source": [
    "# Datasets, dataloaders, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xMoKUTZZEbYH"
   },
   "outputs": [],
   "source": [
    "# Чтобы ускорить обучение, \n",
    "#   заранее ресайзнем все картинки и положим в соседнюю директорию\n",
    "\n",
    "def res_save(item, source_path_nested, resized_path_nested):\n",
    "    im = Image.open(source_path_nested + item)\n",
    "    f, _ = os.path.splitext(source_path_nested + item)\n",
    "    imResize = im.resize((224, 224), Image.ANTIALIAS)\n",
    "    imResize.save(resized_path_nested + item, 'JPEG', quality=95)\n",
    "\n",
    "# train resizing\n",
    "res_save_item = partial(res_save, \n",
    "                        source_path_nested='./data/train/', \n",
    "                        resized_path_nested='./data/train_resized/')\n",
    "\n",
    "! mkdir ./data/train_resized/\n",
    "with multiprocessing.Pool(num_cores) as p:\n",
    "    p.map(res_save_item, os.listdir('./data/train/'))\n",
    "\n",
    "# # test resizing\n",
    "# res_save_item = partial(res_save, \n",
    "#                         source_path_nested='./data/test/', \n",
    "#                         resized_path_nested='./data/test_resized/')\n",
    "\n",
    "# ! mkdir ./data/test_resized/\n",
    "# with multiprocessing.Pool(num_cores) as p:\n",
    "#     p.map(res_save_item, os.listdir('./data/test/'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gnPe-D8EnHJa"
   },
   "outputs": [],
   "source": [
    "# WhaleDataset version for model training with making triplets after getting embeddings\n",
    "\n",
    "class WhaleDataset(Dataset):\n",
    "    def __init__(self, dataset_folder, labels_df, img_loader, transform=None):\n",
    "        self.dataset_folder = dataset_folder\n",
    "        self.labels_df = labels_df\n",
    "        self.transform = transform\n",
    "        self.img_loader = img_loader\n",
    "        \n",
    "        self.image_names = labels_df['Image']\n",
    "        self.image_labels = labels_df['Id_enc']\n",
    "    \n",
    "    def __len__(self):\n",
    "        return labels_df.shape[0]\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        img = self.img_loader(self.dataset_folder + self.image_names[index])\n",
    "        img_label = self.image_labels[index]\n",
    "        \n",
    "        if self.transform is not None:\n",
    "            img = self.transform(img)\n",
    "\n",
    "        return img, img_label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "UBBFALP75FUf"
   },
   "source": [
    "Общая логика формирования тренировочного батча: 50% батча будет состоять из картинок у которых как минимум есть позитивная пара в батче, а остальные 50% достаем рандомно из оставшихся.  \n",
    "Последовательность следующая:\n",
    "1. Идем по labels_unique и достаем из каждого лейбла n_i картинок, где n_i <= self.batch_size_half - batched_positives_num.  \n",
    "Если batched_positives_num < self.batch_size_half то переходим к следующему элементу labels_unique.  \n",
    "batched_positives_num - количество картинок у которых как минимум есть позитивная пара в батче.\n",
    "2. Получается, что вместе с формированием батчей мы перебираем лейблы. Как только они закончатся, мы остановим внутренний цикл и вылетим из условия цикла while.  \n",
    "\n",
    "Из-за формирования labels_unique в init, мы будем каждую эпоху заново создавать объект класса WhaleSampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "24v_oNAH0eZU"
   },
   "outputs": [],
   "source": [
    "class WhaleSampler(BatchSampler):\n",
    "    def __init__(self, labels:np.ndarray, batch_size):\n",
    "        self.labels = labels\n",
    "        \n",
    "        self.labels_unique = np.unique(labels)\n",
    "        # del nw_class\n",
    "        self.labels_unique = np.delete(self.labels_unique, \n",
    "                                       np.where(self.labels_unique == nw_label_enc)[0])\n",
    "        # mix (just in case)\n",
    "        self.labels_unique = np.random.choice(self.labels_unique, \n",
    "                                              len(self.labels_unique), \n",
    "                                              replace=False)\n",
    "        self.labels_unique_len = len(self.labels_unique)\n",
    "        \n",
    "        self.labels_indxs = np.arange(len(labels))\n",
    "        self.label_to_indxs = {label: np.where(labels == label)[0] \n",
    "                               for label in self.labels_unique}\n",
    "        \n",
    "        self.batch_size = batch_size\n",
    "        self.batch_size_half = batch_size // 2\n",
    "        \n",
    "    \n",
    "    def __iter__(self):\n",
    "        current_label = self.labels_unique[0]\n",
    "        while current_label in self.labels_unique:\n",
    "            batch = []\n",
    "            \n",
    "            # batching positives\n",
    "            batched_positives_num = 0\n",
    "            while batched_positives_num < self.batch_size_half:\n",
    "                current_label_indxs = self.label_to_indxs[current_label]\n",
    "                current_label_indxs_len = len(current_label_indxs)\n",
    "                \n",
    "                # get positives from current_label\n",
    "                if current_label_indxs_len < self.batch_size_half - batched_positives_num:\n",
    "                    batch.extend(current_label_indxs)\n",
    "                    \n",
    "                    batched_positives_num += current_label_indxs_len\n",
    "                    \n",
    "                    next_label_pos = np.where(self.labels_unique == current_label)[0][0] + 1\n",
    "                    if next_label_pos < self.labels_unique_len - 1:\n",
    "                        current_label = self.labels_unique[next_label_pos]\n",
    "                    else: \n",
    "                        # only for out from loop while current_label in self.labels_unique:\n",
    "                        current_label = 1e+6\n",
    "                        break\n",
    "                else:\n",
    "                    batch.extend(\n",
    "                        np.random.choice(current_label_indxs, \n",
    "                                         self.batch_size_half - batched_positives_num, \n",
    "                                         replace=False)\n",
    "                    )\n",
    "                    \n",
    "                    batched_positives_num += self.batch_size_half - batched_positives_num\n",
    "                    \n",
    "                    next_label_pos = np.where(self.labels_unique == current_label)[0][0] + 1\n",
    "                    if next_label_pos < self.labels_unique_len - 1:\n",
    "                        current_label = self.labels_unique[next_label_pos]\n",
    "                    else: \n",
    "                        # only for out from loop while current_label in self.labels_unique:\n",
    "                        current_label = 1e+6\n",
    "                        break\n",
    "                \n",
    "            # batching negatives\n",
    "            batch.extend(\n",
    "                np.random.choice(self.labels_indxs, \n",
    "                                 self.batch_size - self.batch_size_half, \n",
    "                                 replace=False)\n",
    "            )\n",
    "            \n",
    "            yield batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vgsZcvH2VxOs"
   },
   "outputs": [],
   "source": [
    "mean = [0.485, 0.456, 0.406]\n",
    "std = [0.229, 0.224, 0.225]\n",
    "\n",
    "data_transforms = transforms.Compose([\n",
    "#     transforms.ToPILImage(),\n",
    "#     transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean, std)\n",
    "])\n",
    "\n",
    "def imgshow_tensor(img):\n",
    "    img = img.numpy().transpose((1,2,0))\n",
    "    img = img * std + mean\n",
    "    plt.imshow(img)\n",
    "    plt.grid(False)\n",
    "    plt.pause(0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "e_dQirKprbid"
   },
   "outputs": [],
   "source": [
    "# Dataset для валидации. Тут триплеты собираются при инициализации\n",
    "\n",
    "class WhaleDataset_val(Dataset):\n",
    "    def __init__(self, dataset_folder, labels_df, mode='val', transform=None):\n",
    "        self.dataset_folder = dataset_folder\n",
    "        self.labels_df = labels_df\n",
    "        self.image_names = labels_df['Image']\n",
    "        self.mode = mode\n",
    "        self.transform = transform\n",
    "        \n",
    "        if mode == 'val':\n",
    "            self.not_nw_indxs = labels_df[labels_df['Id'] != 'new_whale'].index\n",
    "            self.labels_set = set(labels_df['Id_enc'])\n",
    "            self.label_to_indices = {label: np.where(labels_df['Id_enc'] == label)[0]\n",
    "                                     for label in self.labels_set}\n",
    "            \n",
    "            random_state = np.random.RandomState(42)\n",
    "            triplets = [\n",
    "                [\n",
    "                    self.image_names[indx],\n",
    "                    self.image_names[\n",
    "                        random_state.choice(\n",
    "                            self.label_to_indices[labels_df['Id_enc'][indx]]\n",
    "                        )\n",
    "                    ],\n",
    "                    self.image_names[\n",
    "                        random_state.choice(\n",
    "                            self.label_to_indices[\n",
    "                                np.random.choice(\n",
    "                                    list(\n",
    "                                        self.labels_set - set([labels_df['Id_enc'][indx]])\n",
    "                                    )\n",
    "                                )\n",
    "                            ]\n",
    "                        )\n",
    "                    ]\n",
    "                ]\n",
    "                for indx in self.not_nw_indxs\n",
    "            ]\n",
    "            self.triplets = triplets\n",
    "    \n",
    "    def __len__(self):\n",
    "        if self.mode != 'test':\n",
    "            return len(self.not_nw_indxs)\n",
    "        elif self.mode == 'test':\n",
    "            return self.labels_df.shape[0]\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        if self.mode == 'val':\n",
    "            path1, path2, path3 = self.triplets[index]\n",
    "            img1 = Image.open(self.dataset_folder + path1).convert('RGB')\n",
    "            img2 = Image.open(self.dataset_folder + path2).convert('RGB')\n",
    "            img3 = Image.open(self.dataset_folder + path3).convert('RGB')\n",
    "            \n",
    "            if self.transform is not None:\n",
    "                img1 = self.transform(img1)\n",
    "                img2 = self.transform(img2)\n",
    "                img3 = self.transform(img3)\n",
    "        \n",
    "            return img1, img2, img3\n",
    "        \n",
    "        elif self.mode == 'test':\n",
    "            img1 = Image.open(self.dataset_folder + self.image_names[index]).convert('RGB')\n",
    "            \n",
    "            if self.transform is not None:\n",
    "                img1 = self.transform(img1)\n",
    "            \n",
    "            return img1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "OGGtHl-eiZq8"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "dSdQlY59OtV-"
   },
   "source": [
    "# Make preds and metrics calculating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "v6C4iHrNXIef"
   },
   "outputs": [],
   "source": [
    "# mAP@5\n",
    "\n",
    "def map_per_image(label, predictions):\n",
    "    \"\"\"Computes the precision score of one image.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    label : string\n",
    "            The true label of the image\n",
    "    predictions : list\n",
    "            A list of predicted elements (order does matter, 5 predictions allowed per image)\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    score : double\n",
    "    \"\"\"    \n",
    "    try:\n",
    "        return 1 / (predictions[:5].index(label) + 1)\n",
    "    except ValueError:\n",
    "        return 0.0\n",
    "\n",
    "def map_per_set(labels, predictions):\n",
    "    \"\"\"Computes the average over multiple images.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    labels : list\n",
    "             A list of the true labels. (Only one true label per images allowed!)\n",
    "    predictions : list of list\n",
    "             A list of predicted elements (order does matter, 5 predictions allowed per image)\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    score : double\n",
    "    \"\"\"\n",
    "    return np.mean([map_per_image(l, p) for l, p in zip(labels, predictions)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Ux7E2J5cLhSp"
   },
   "source": [
    "Предикты делаем предельно просто: прогоняем через сеть весь тестовый и тренировочный датасеты, получаем эмбеддинги, считаем расстояния всех тестовых эмбеддингов со всеми тренировочными. После, для каждого тестового объекта находим индекс тренировочного объекта с минимальным расстоянием."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "99OqCfyp-RFt"
   },
   "outputs": [],
   "source": [
    "def batch_gen(iterable, batch_size=1):\n",
    "    l = len(iterable)\n",
    "    for ndx in range(0, l, batch_size):\n",
    "        yield iterable[ndx:min(ndx + batch_size, l)]\n",
    "\n",
    "\n",
    "class make_preds():\n",
    "    def __init__(self):\n",
    "        self.dataset_folders = {'train': None, 'test': None}\n",
    "        self.label_dfs = {'train': None, 'test': None}\n",
    "        self.distances = None\n",
    "        self.len_embdd = None\n",
    "\n",
    "\n",
    "    def calc_embeddings(self, model, embedding_type,\n",
    "                       dataset_folder, labels_df, transforms, \n",
    "                       batch_size=2**5, num_workers=4):\n",
    "        assert embedding_type in ['train', 'test'], \\\n",
    "            \"embedding_type must be in ['train', 'test']\"\n",
    "        self.dataset_folders.update({embedding_type: labels_df})\n",
    "        self.label_dfs.update({embedding_type: labels_df})\n",
    "        \n",
    "        model.to(cuda)\n",
    "        model.eval()\n",
    "\n",
    "        test_dataset = WhaleDataset_val(dataset_folder=dataset_folder, \n",
    "                                        labels_df=labels_df, \n",
    "                                        mode='test', \n",
    "                                        transform=transforms)\n",
    "        inference_loader = torch.utils.data.DataLoader(dataset=test_dataset, \n",
    "                                                       batch_size=batch_size, \n",
    "                                                       shuffle=False, \n",
    "                                                       num_workers=num_workers)\n",
    "\n",
    "        embeddings = torch.Tensor().to(cuda)\n",
    "\n",
    "        for data in tqdm(inference_loader, desc='calc embeddings', position=0):\n",
    "            data = data.to(cuda)\n",
    "\n",
    "            with torch.no_grad():        \n",
    "                embd = model.get_embedding(data)\n",
    "                embeddings = torch.cat((embeddings, embd))\n",
    "        \n",
    "        if embedding_type == 'train':\n",
    "            self.train_embdds = embeddings\n",
    "        elif embedding_type == 'test':\n",
    "            self.test_embdds = embeddings\n",
    "        \n",
    "        del test_dataset, inference_loader, data, embeddings\n",
    "\n",
    "\n",
    "    def get_distances(self, batch_dist_size=20):\n",
    "        self.num_train_embdds = self.train_embdds.shape[0]\n",
    "        self.num_test_embdds = self.test_embdds.shape[0]\n",
    "        self.len_embdd = self.test_embdds.shape[1]\n",
    "        \n",
    "        batch_indxs = [*batch_gen(np.arange(self.num_test_embdds), \n",
    "                                  batch_size=batch_dist_size)]\n",
    "        distances = torch.Tensor([]).view((0, self.num_train_embdds)).to(cuda)\n",
    "        \n",
    "        for batch in tqdm(batch_indxs, desc='calc distances', position=0):            \n",
    "            dist = torch.norm((self.test_embdds[batch].view(-1, 1, self.len_embdd) - self.train_embdds), \n",
    "                              dim=-1)\n",
    "            distances = torch.cat((distances, dist))\n",
    "        \n",
    "        self.distances = distances.to(cpu).numpy()\n",
    "        del dist, distances\n",
    "\n",
    "\n",
    "    def get_preds(self, num_preds=5, agg_func='min'):\n",
    "        distances = pd.DataFrame(self.distances.T)\n",
    "        distances['label'] = self.label_dfs['train']['Id_enc'].values\n",
    "        distances = distances.groupby('label').agg([agg_func]).values\n",
    "\n",
    "        self.pred_indxs = np.argsort(distances.T)\n",
    "        pred_labels = np.array([*map(lambda row: lblenc.inverse_transform(row), \n",
    "                                     self.pred_indxs[:, 0:num_preds])])\n",
    "\n",
    "        return pred_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8IW2nPN_1Ofd"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "6e4187774db71cc55a61cc83ddb66bd5d882ae39",
    "colab_type": "text",
    "id": "sF3J4AM1W9ti"
   },
   "source": [
    "# Net architecture & training process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "4a4a5b0b67302aa1e01c062bb1bc814e4f53fec0",
    "colab": {},
    "colab_type": "code",
    "id": "QNosih7ZW9tz"
   },
   "outputs": [],
   "source": [
    "class siamese_net(nn.Module):\n",
    "    def __init__(self, encoder_net, loss_margin):\n",
    "        super(siamese_net, self).__init__()\n",
    "        self.encoder_net = encoder_net\n",
    "        self.loss_margin = loss_margin\n",
    "        \n",
    "    def forward(self, x, labels, size_average=True):\n",
    "        embeddings = self.encoder_net(x)\n",
    "        \n",
    "        # deviding on L2 norm (FaceNet)\n",
    "        embeddings = embeddings / torch.norm(embeddings, dim=-1).view(-1, 1)\n",
    "        \n",
    "        distances = torch.norm(\n",
    "            (embeddings[:batch_size // 2].view(-1, 1, embeddings.size()[-1]) - embeddings), dim=-1\n",
    "        )\n",
    "        \n",
    "        identities_matrix = labels[:batch_size // 2].view(-1, 1) - labels\n",
    "        \n",
    "        # getting distances for hard positives imgs\n",
    "        identities_mask_pos = identities_matrix == 0\n",
    "        identities_dist_pos = distances * identities_mask_pos.type(torch.cuda.FloatTensor)\n",
    "        dist_pos = torch.max(identities_dist_pos, dim=-1)[0]\n",
    "        \n",
    "        # getting distances for hard negatives imgs\n",
    "        identities_mask_neg = identities_matrix != 0\n",
    "        identities_dist_neg = distances * identities_mask_neg.type(torch.cuda.FloatTensor)\n",
    "        identities_dist_neg[identities_dist_neg == 0] = 1e+6 # needed just for not to brake min func\n",
    "        dist_neg = torch.min(identities_dist_neg, dim=-1)[0]\n",
    "        \n",
    "        #calc loss\n",
    "        losses = F.relu(dist_pos - dist_neg + self.loss_margin)\n",
    "        return losses.mean() if size_average else losses.sum()\n",
    "        \n",
    "    def get_embedding(self, x):\n",
    "        return self.encoder_net(x)\n",
    "    \n",
    "    def forward_val(self, x1, x2, x3):\n",
    "        x1 = self.encoder_net(x1)\n",
    "        x1 = x1 / torch.norm(x1, dim=-1).view(-1, 1)\n",
    "        \n",
    "        x2 = self.encoder_net(x2)\n",
    "        x2 = x2 / torch.norm(x2, dim=-1).view(-1, 1)\n",
    "        \n",
    "        x3 = self.encoder_net(x3)\n",
    "        x3 = x3 / torch.norm(x3, dim=-1).view(-1, 1)\n",
    "        \n",
    "        return x1, x2, x3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "27c66f36b3a61afeaf95607b2280ad20c4c01db8",
    "colab": {},
    "colab_type": "code",
    "id": "JOeYYN4rW9t3"
   },
   "outputs": [],
   "source": [
    "def plot_save_logs(logs, model_name:str, y_lim=2.05, is_plot=True):\n",
    "    \"\"\"\n",
    "    logs example:\n",
    "    {\n",
    "        'loss': {\n",
    "            'train': [1, 1.5, 0.5, 0.3, 0.2],\n",
    "            'val_y': [0.5, 0.3],\n",
    "            'val_x': [600, 1200]\n",
    "        },\n",
    "        'metrics': {\n",
    "            'value': [...],\n",
    "            'epoch': [...]\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    \"\"\"\n",
    "    with open(gdrive_path + model_name + '_logs.pkl', 'wb') as f:\n",
    "        pickle.dump(logs, f, pickle.HIGHEST_PROTOCOL)\n",
    "    \n",
    "    if is_plot == True:\n",
    "        fig, ax = plt.subplots(2, 1, figsize=(7, 10))\n",
    "\n",
    "        ax[0].plot(logs['loss']['train'], label='train', zorder=1)\n",
    "        ax[0].scatter(x=logs['loss']['val_x'], y=logs['loss']['val_y'], label='val', \n",
    "                      zorder=2, marker='+', s=180, c='orange')\n",
    "\n",
    "        ax[0].set(title = 'loss', xlabel='batch num', ylim=(-0.05, y_lim))\n",
    "        ax[0].legend(loc='best')\n",
    "        ax[0].grid(True)\n",
    "\n",
    "\n",
    "        ax[1].scatter(x=logs['metrics']['epoch'], y=logs['metrics']['value'], \n",
    "                      marker='+', s=180, c='blue')\n",
    "\n",
    "        ax[1].set(title = 'mAP', xlabel='epoch num')\n",
    "        ax[1].grid(True)\n",
    "\n",
    "        fig.tight_layout()\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "6f720aefd4ad5052acfd73dbe61cebd159dc051c",
    "colab": {},
    "colab_type": "code",
    "id": "wMQ8D4JrW9t5"
   },
   "outputs": [],
   "source": [
    "def train_model(model, optimizer, train_loader, num_epochs, \n",
    "                model_name, margin, val_loader=None): \n",
    "    logs = {\n",
    "        'loss': {'train': [], 'val_y': [], 'val_x': []},\n",
    "        'metrics': {'value': [], 'epoch': []}\n",
    "    }\n",
    "    \n",
    "    model.to(cuda)\n",
    "    for epoch in range(num_epochs):\n",
    "        # training process\n",
    "        new_train_sampler = WhaleSampler(labels=new_train_labels_without['Id_enc'].values, \n",
    "                                         batch_size=120)\n",
    "        train_loader = torch.utils.data.DataLoader(dataset=new_train_dataset,\n",
    "                                           batch_sampler=new_train_sampler,\n",
    "                                           shuffle=False,\n",
    "                                           num_workers=7,\n",
    "                                           pin_memory=True)\n",
    "        \n",
    "        model.train()\n",
    "        for x, labels in tqdm(train_loader, desc='training', position=0):\n",
    "            optimizer.zero_grad()\n",
    "            x, labels = x.to(cuda, non_blocking=True), labels.to(cuda, non_blocking=True)\n",
    "            \n",
    "            loss = model.forward(x, labels)\n",
    "            \n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            logs['loss']['train'].append(loss.item())\n",
    "            \n",
    "            # plot graphs and save model\n",
    "            clear_output()\n",
    "            print('\\n', 'epoch=', epoch)\n",
    "            plot_save_logs(logs, model_name, is_plot=True)\n",
    "            \n",
    "        # validating process\n",
    "        if val_loader != None:\n",
    "            loss_val_batch = []\n",
    "            model.eval()\n",
    "            \n",
    "            # тут используется другой Dataset -- сразу возвращаются триплеты\n",
    "            # calculating loss\n",
    "            for data in tqdm(val_loader, desc='validation', position=0):\n",
    "                with torch.no_grad():\n",
    "                    data = tuple(d.to(cuda, non_blocking=True) for d in data)\n",
    "\n",
    "                    outputs = model.forward_val(*data)\n",
    "\n",
    "                    loss = F.triplet_margin_loss(*outputs, margin=margin).item() # 1\n",
    "                    loss_val_batch.append(loss)\n",
    "            \n",
    "            logs['loss']['val_y'].append(np.mean(loss_val_batch))\n",
    "            logs['loss']['val_x'].append(len(logs['loss']['train']) - 1)\n",
    "            \n",
    "            # calculating metrics\n",
    "            embedds_preds.calc_embeddings(model=model,\n",
    "                                          embedding_type='train',\n",
    "                                          dataset_folder='./data/train_resized/',\n",
    "                                          labels_df=new_train_labels_with,\n",
    "                                          transforms=data_transforms)\n",
    "            embedds_preds.calc_embeddings(model=model,\n",
    "                                          embedding_type='test',\n",
    "                                          dataset_folder='./data/train_resized/',\n",
    "                                          labels_df=val_labels_df,\n",
    "                                          transforms=data_transforms)\n",
    "            \n",
    "            embedds_preds.get_distances(batch_dist_size=10)\n",
    "            preds = embedds_preds.get_preds()\n",
    "            mean_ap = map_per_set(val_labels_df['Id'].values.tolist(), preds.tolist())\n",
    "            \n",
    "            logs['metrics']['value'].append(mean_ap)\n",
    "            logs['metrics']['epoch'].append(epoch)\n",
    "            \n",
    "            # plot graphs\n",
    "            clear_output()\n",
    "            plot_save_logs(logs, model_name, is_plot=True)\n",
    "        \n",
    "        # saving model\n",
    "        state = {'model': model.state_dict(), 'optimizer': optimizer.state_dict()}\n",
    "        save_path = gdrive_path + model_name + '_state.pth'\n",
    "        torch.save(state, save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fidqe704UJCr"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "mMQj-q6AUGGh"
   },
   "source": [
    "# Net training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dpqMpKWeUzKk"
   },
   "outputs": [],
   "source": [
    "resnet50 = models.resnet50(pretrained=False)\n",
    "# resnet101 = models.resnet101(pretrained=False)\n",
    "\n",
    "encoder = resnet50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "McxedNiaUEox"
   },
   "outputs": [],
   "source": [
    "# Encoder modifs\n",
    "\n",
    "# Modif version 0\n",
    "# encoder = nn.Sequential(*(list(encoder.children())[:-1]))\n",
    "\n",
    "# Modif version 1\n",
    "# снижение размерности эмбеддингов могут показывать лучший результат на ранних эпохах (FaceNet)\n",
    "encoder.fc = nn.Sequential(nn.Linear(2048, 1024),\n",
    "                           nn.ReLU(),\n",
    "                           nn.Linear(1024, 256)\n",
    "                          )\n",
    "\n",
    "# Modif version 2\n",
    "# encoder.conv1 = nn.Conv2d(1, 64, kernel_size=7, stride=2, padding=3, bias=False)\n",
    "# encoder.fc = nn.Sequential(nn.Linear(2048, 1024),\n",
    "#                            nn.ReLU(),\n",
    "#                            nn.Linear(1024, 256)\n",
    "#                           )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "5cd48580f1bce5bcc4113c69c2c39f325d850430",
    "colab": {},
    "colab_type": "code",
    "id": "jLjBSmThW9t7"
   },
   "outputs": [],
   "source": [
    "# training on train set with validation part\n",
    "pil_imopen = lambda x: Image.open(x).convert('RGB')\n",
    "\n",
    "\n",
    "new_train_dataset = WhaleDataset(dataset_folder='./data/train_resized/',\n",
    "                                 labels_df=new_train_labels_without,\n",
    "                                 img_loader=pil_imopen,\n",
    "                                 transform=data_transforms)\n",
    "\n",
    "new_train_sampler = WhaleSampler(labels=new_train_labels_without['Id_enc'].values, \n",
    "                                 batch_size=150)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(dataset=new_train_dataset,\n",
    "                                           batch_sampler=new_train_sampler,\n",
    "                                           shuffle=False,\n",
    "                                           num_workers=10,\n",
    "                                           pin_memory=True)\n",
    "\n",
    "\n",
    "val_dataset = WhaleDataset_val(dataset_folder='./data/train_resized/', \n",
    "                               labels_df=val_labels_df, \n",
    "                               mode='val', \n",
    "                               transform=data_transforms)\n",
    "\n",
    "val_loader = torch.utils.data.DataLoader(dataset=val_dataset, \n",
    "                                         batch_size=38, \n",
    "                                         shuffle=False, \n",
    "                                         num_workers=10,\n",
    "                                         pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1538
    },
    "colab_type": "code",
    "id": "-7xmWvBcKSSH",
    "outputId": "e6e3251a-105a-4dd4-e567-fdd02676d311"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " epoch= 5\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 504x720 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training: 152it [02:14,  1.19it/s]\n",
      "validation:  55%|█████▌    | 46/83 [00:10<00:07,  4.97it/s]Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ignatlegeza/anaconda3/lib/python3.7/multiprocessing/queues.py\", line 242, in _feed\n",
      "    send_bytes(obj)\n",
      "  File \"/home/ignatlegeza/anaconda3/lib/python3.7/multiprocessing/connection.py\", line 200, in send_bytes\n",
      "    self._send_bytes(m[offset:offset + size])\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ignatlegeza/anaconda3/lib/python3.7/multiprocessing/queues.py\", line 242, in _feed\n",
      "    send_bytes(obj)\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ignatlegeza/anaconda3/lib/python3.7/multiprocessing/queues.py\", line 242, in _feed\n",
      "    send_bytes(obj)\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ignatlegeza/anaconda3/lib/python3.7/multiprocessing/queues.py\", line 242, in _feed\n",
      "    send_bytes(obj)\n",
      "  File \"/home/ignatlegeza/anaconda3/lib/python3.7/multiprocessing/connection.py\", line 200, in send_bytes\n",
      "    self._send_bytes(m[offset:offset + size])\n",
      "  File \"/home/ignatlegeza/anaconda3/lib/python3.7/multiprocessing/connection.py\", line 404, in _send_bytes\n",
      "    self._send(header + buf)\n",
      "  File \"/home/ignatlegeza/anaconda3/lib/python3.7/multiprocessing/queues.py\", line 242, in _feed\n",
      "    send_bytes(obj)\n",
      "  File \"/home/ignatlegeza/anaconda3/lib/python3.7/multiprocessing/connection.py\", line 200, in send_bytes\n",
      "    self._send_bytes(m[offset:offset + size])\n",
      "  File \"/home/ignatlegeza/anaconda3/lib/python3.7/multiprocessing/connection.py\", line 404, in _send_bytes\n",
      "    self._send(header + buf)\n",
      "  File \"/home/ignatlegeza/anaconda3/lib/python3.7/multiprocessing/connection.py\", line 368, in _send\n",
      "    n = write(self._handle, buf)\n",
      "BrokenPipeError: [Errno 32] Broken pipe\n",
      "  File \"/home/ignatlegeza/anaconda3/lib/python3.7/multiprocessing/connection.py\", line 368, in _send\n",
      "    n = write(self._handle, buf)\n",
      "BrokenPipeError: [Errno 32] Broken pipe\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ignatlegeza/anaconda3/lib/python3.7/multiprocessing/queues.py\", line 242, in _feed\n",
      "    send_bytes(obj)\n",
      "  File \"/home/ignatlegeza/anaconda3/lib/python3.7/multiprocessing/connection.py\", line 200, in send_bytes\n",
      "    self._send_bytes(m[offset:offset + size])\n",
      "  File \"/home/ignatlegeza/anaconda3/lib/python3.7/multiprocessing/connection.py\", line 404, in _send_bytes\n",
      "    self._send(header + buf)\n",
      "  File \"/home/ignatlegeza/anaconda3/lib/python3.7/multiprocessing/connection.py\", line 368, in _send\n",
      "    n = write(self._handle, buf)\n",
      "  File \"/home/ignatlegeza/anaconda3/lib/python3.7/multiprocessing/connection.py\", line 200, in send_bytes\n",
      "    self._send_bytes(m[offset:offset + size])\n",
      "  File \"/home/ignatlegeza/anaconda3/lib/python3.7/multiprocessing/connection.py\", line 404, in _send_bytes\n",
      "    self._send(header + buf)\n",
      "  File \"/home/ignatlegeza/anaconda3/lib/python3.7/multiprocessing/connection.py\", line 368, in _send\n",
      "    n = write(self._handle, buf)\n",
      "BrokenPipeError: [Errno 32] Broken pipe\n",
      "  File \"/home/ignatlegeza/anaconda3/lib/python3.7/multiprocessing/queues.py\", line 242, in _feed\n",
      "    send_bytes(obj)\n",
      "  File \"/home/ignatlegeza/anaconda3/lib/python3.7/multiprocessing/connection.py\", line 200, in send_bytes\n",
      "    self._send_bytes(m[offset:offset + size])\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ignatlegeza/anaconda3/lib/python3.7/multiprocessing/queues.py\", line 242, in _feed\n",
      "    send_bytes(obj)\n",
      "  File \"/home/ignatlegeza/anaconda3/lib/python3.7/multiprocessing/connection.py\", line 200, in send_bytes\n",
      "    self._send_bytes(m[offset:offset + size])\n",
      "  File \"/home/ignatlegeza/anaconda3/lib/python3.7/multiprocessing/connection.py\", line 404, in _send_bytes\n",
      "    self._send(header + buf)\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ignatlegeza/anaconda3/lib/python3.7/multiprocessing/queues.py\", line 242, in _feed\n",
      "    send_bytes(obj)\n",
      "  File \"/home/ignatlegeza/anaconda3/lib/python3.7/multiprocessing/connection.py\", line 200, in send_bytes\n",
      "    self._send_bytes(m[offset:offset + size])\n",
      "  File \"/home/ignatlegeza/anaconda3/lib/python3.7/multiprocessing/connection.py\", line 404, in _send_bytes\n",
      "    self._send(header + buf)\n",
      "  File \"/home/ignatlegeza/anaconda3/lib/python3.7/multiprocessing/connection.py\", line 368, in _send\n",
      "    n = write(self._handle, buf)\n",
      "BrokenPipeError: [Errno 32] Broken pipe\n",
      "  File \"/home/ignatlegeza/anaconda3/lib/python3.7/multiprocessing/connection.py\", line 404, in _send_bytes\n",
      "    self._send(header + buf)\n",
      "  File \"/home/ignatlegeza/anaconda3/lib/python3.7/multiprocessing/connection.py\", line 368, in _send\n",
      "    n = write(self._handle, buf)\n",
      "  File \"/home/ignatlegeza/anaconda3/lib/python3.7/multiprocessing/connection.py\", line 200, in send_bytes\n",
      "    self._send_bytes(m[offset:offset + size])\n",
      "BrokenPipeError: [Errno 32] Broken pipe\n",
      "BrokenPipeError: [Errno 32] Broken pipe\n",
      "  File \"/home/ignatlegeza/anaconda3/lib/python3.7/multiprocessing/connection.py\", line 404, in _send_bytes\n",
      "    self._send(header + buf)\n",
      "  File \"/home/ignatlegeza/anaconda3/lib/python3.7/multiprocessing/connection.py\", line 368, in _send\n",
      "    n = write(self._handle, buf)\n",
      "  File \"/home/ignatlegeza/anaconda3/lib/python3.7/multiprocessing/connection.py\", line 404, in _send_bytes\n",
      "    self._send(header + buf)\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ignatlegeza/anaconda3/lib/python3.7/multiprocessing/connection.py\", line 368, in _send\n",
      "    n = write(self._handle, buf)\n",
      "  File \"/home/ignatlegeza/anaconda3/lib/python3.7/multiprocessing/queues.py\", line 242, in _feed\n",
      "    send_bytes(obj)\n",
      "  File \"/home/ignatlegeza/anaconda3/lib/python3.7/multiprocessing/connection.py\", line 200, in send_bytes\n",
      "    self._send_bytes(m[offset:offset + size])\n",
      "BrokenPipeError: [Errno 32] Broken pipe\n",
      "BrokenPipeError: [Errno 32] Broken pipe\n",
      "  File \"/home/ignatlegeza/anaconda3/lib/python3.7/multiprocessing/connection.py\", line 404, in _send_bytes\n",
      "    self._send(header + buf)\n",
      "  File \"/home/ignatlegeza/anaconda3/lib/python3.7/multiprocessing/connection.py\", line 368, in _send\n",
      "    n = write(self._handle, buf)\n",
      "BrokenPipeError: [Errno 32] Broken pipe\n",
      "  File \"/home/ignatlegeza/anaconda3/lib/python3.7/multiprocessing/connection.py\", line 368, in _send\n",
      "    n = write(self._handle, buf)\n",
      "BrokenPipeError: [Errno 32] Broken pipe\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-36-4480538c0324>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m train_model(model=resnet_50_hard_triplets, optimizer=optmzr, train_loader=train_loader, \n\u001b[1;32m     10\u001b[0m             \u001b[0mnum_epochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'resnet_50_hard_triplets_mg1_v2'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmargin\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmargin\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m             val_loader=val_loader)\n\u001b[0m",
      "\u001b[0;32m<ipython-input-24-9a9b7bd25e63>\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(model, optimizer, train_loader, num_epochs, model_name, margin, val_loader)\u001b[0m\n\u001b[1;32m     46\u001b[0m                     \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward_val\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 48\u001b[0;31m                     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtriplet_margin_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmargin\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmargin\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# 1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     49\u001b[0m                     \u001b[0mloss_val_batch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "margin = 1\n",
    "batch_size = 100\n",
    "\n",
    "resnet_50_hard_triplets = siamese_net(encoder_net=encoder, loss_margin=margin)\n",
    "\n",
    "optmzr = optim.Adam(resnet_50_hard_triplets.parameters(), lr=1e-3)\n",
    "\n",
    "embedds_preds = make_preds()\n",
    "train_model(model=resnet_50_hard_triplets, optimizer=optmzr, train_loader=train_loader, \n",
    "            num_epochs=50, model_name='resnet_50_hard_triplets_mg1_v2', margin=margin, \n",
    "            val_loader=val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jgUTRW5uzAuD"
   },
   "outputs": [],
   "source": [
    "  "
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "whales_clf_public.ipynb",
   "provenance": [],
   "toc_visible": true,
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
